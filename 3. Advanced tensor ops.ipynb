{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98accc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f08b441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1753, -2.0216,  0.3046, -0.6500],\n",
      "        [ 0.0166,  0.6468,  0.2631, -1.1282],\n",
      "        [-0.0263,  0.3400, -0.6799, -0.1814]])\n"
     ]
    }
   ],
   "source": [
    "# Q1: Create a 3x4 tensor of random values from a normal distribution with mean=0 and std=1\n",
    "# Then convert it to run on GPU if available\n",
    "\n",
    "a = torch.randn(3,4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor = a.to(device)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85501fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q2: Create a tensor containing values from 0 to 11 (inclusive), then reshape it to a 3x4 matrix\n",
    "# What's the difference between using dtype=torch.float vs torch.float32?\n",
    "\n",
    "# Your code here\n",
    "\n",
    "a = torch.arange(0,12)\n",
    "print(a)\n",
    "a = a.reshape(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8303a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0702e-01, 8.2573e-01, 9.8399e-01,  ..., 5.1761e-01, 5.4951e-01,\n",
       "         1.1465e-01],\n",
       "        [8.4487e-01, 6.3307e-01, 5.1034e-01,  ..., 5.1491e-01, 2.7994e-01,\n",
       "         5.6022e-01],\n",
       "        [8.1599e-05, 1.1812e-02, 7.6539e-01,  ..., 4.5400e-01, 9.5237e-01,\n",
       "         6.7598e-01],\n",
       "        ...,\n",
       "        [4.1425e-01, 2.2368e-01, 9.1491e-01,  ..., 1.2090e-01, 6.5530e-01,\n",
       "         4.6776e-01],\n",
       "        [7.6319e-01, 4.6062e-01, 6.8564e-02,  ..., 9.5889e-01, 5.9045e-01,\n",
       "         5.9571e-01],\n",
       "        [6.6688e-02, 2.0688e-02, 2.0247e-01,  ..., 9.4749e-01, 5.8343e-01,\n",
       "         2.5525e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3: Given a batch of 10 images (each 3x28x28), reshape it for a linear layer that expects [batch_size, features]\n",
    "images = torch.rand(10, 3, 28, 28)\n",
    "\n",
    "images = images.view(images.size(0) , -1)\n",
    "images\n",
    "\n",
    "\n",
    "# Explanation:\n",
    "# images.size(0) gets the batch size (10 in this case).\n",
    "\n",
    "# -1 tells PyTorch to infer the remaining dimension (3*28*28 = 2352).\n",
    "\n",
    "# .view(...) is used to reshape the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf82a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4: Add a \"channel\" dimension to a 2D grayscale image tensor of shape [28, 28]\n",
    "img = torch.rand(28, 28)\n",
    "print(img.shape)\n",
    "img = img.unsqueeze(0)\n",
    "print(img.shape)\n",
    "\n",
    "img = img.repeat(3, 1, 1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2df21b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5: Convert tensor of shape [batch_size, seq_len, hidden_size] to [seq_len, batch_size, hidden_size]\n",
    "# (common operation in RNNs)\n",
    "x = torch.rand(32, 10, 512)  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "x = x.permute(1, 0, 2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13fad5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3,  5],\n",
       "        [ 7,  9, 11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6: Extract all even-indexed columns from the following matrix\n",
    "matrix = torch.tensor([[1, 2, 3, 4, 5, 6],\n",
    "                       [7, 8, 9, 10, 11, 12]])\n",
    "\n",
    "matrix = matrix[:, ::2]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3098054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 0],\n",
       "        [4, 0, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7: For this tensor, set all negative values to zero without using loops\n",
    "data = torch.tensor([[-1, 2, -3], [4, -5, 6]])\n",
    "\n",
    "data = torch.clamp(data, min=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55890184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# Q8: Extract elements from this tensor where the corresponding mask is True\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "mask = torch.tensor([True, False, True, False, True])\n",
    "\n",
    "\n",
    "# Extract elements where mask is True\n",
    "selected = tensor[mask]\n",
    "\n",
    "print(selected)  # Output: tensor([1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ea4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 1])\n",
      "torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Q9: Add a different bias to each channel of this batch of images without loops\n",
    "# image shape: [batch_size, channels, height, width]\n",
    "images = torch.rand(8, 3, 32, 32)\n",
    "channel_biases = torch.tensor([0.5, -0.5, 0.2])\n",
    "\n",
    "b = channel_biases.unsqueeze(0)\n",
    "b = b.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "print(b.shape)\n",
    "\n",
    "\n",
    "\n",
    "# OR WE HAVE ANOTHER BETTER WAY TO DO THIS \n",
    "\n",
    "\n",
    "biases = channel_biases.view(1, -1, 1, 1)\n",
    "print(biases.shape)\n",
    "result = images + biases\n",
    "# Means:\n",
    "# - 1: batch dimension (so PyTorch broadcasts the same biases to all images)\n",
    "# - -1: keep the number of channels (PyTorch infers it from the original tensor, which is 3 here)\n",
    "# - 1: height (will be broadcast across all pixels vertically)\n",
    "# - 1: width  (will be broadcast across all pixels horizontally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b784a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q10: Multiply each row of matrix A by the corresponding element in vector b\n",
    "A = torch.rand(5, 3)  # 5 rows, 3 columns\n",
    "b = torch.tensor([1, 2, 3, 4, 5])  # 5 elements\n",
    "\n",
    "b = b.unsqueeze(-1)\n",
    "print(b.shape)\n",
    "\n",
    "A*b\n",
    "\n",
    "\n",
    "\n",
    "# OR WE COULD HAVE DONE THIS\n",
    "\n",
    "# Reshape b to [5, 1] to broadcast along columns\n",
    "b_reshaped = b.view(-1, 1)\n",
    "print(b_reshaped.shape)\n",
    "# Multiply each row of A by the corresponding element in b\n",
    "result = A * b_reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b929c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_expand shape: torch.Size([5, 3, 3])\n",
      "batch_repeat shape: torch.Size([5, 3, 3])\n",
      "Memory usage (expand): 180 bytes\n",
      "Memory usage (repeat): 180 bytes\n"
     ]
    }
   ],
   "source": [
    "# Q14: Create a 3x3 identity matrix, then use both expand() and repeat() to create a \n",
    "# batch of 5 identical matrices. \n",
    "identity = torch.eye(3)\n",
    "\n",
    "\n",
    "batch_expand = identity.unsqueeze(0).expand(5, 3, 3)\n",
    "batch_repeat = identity.unsqueeze(0).repeat(5, 1, 1)\n",
    "\n",
    "\n",
    "print(\"batch_expand shape:\", batch_expand.shape)\n",
    "print(\"batch_repeat shape:\", batch_repeat.shape)\n",
    "\n",
    "\n",
    "print(\"Memory usage (expand):\", batch_expand.element_size() * batch_expand.nelement(), \"bytes\")\n",
    "print(\"Memory usage (repeat):\", batch_repeat.element_size() * batch_repeat.nelement(), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d5cc8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2251, 0.4902, 1.0756, 0.7053],\n",
       "         [1.0119, 0.8393, 0.6483, 1.2902]],\n",
       "\n",
       "        [[1.0820, 0.4686, 1.6974, 0.3871],\n",
       "         [1.8687, 0.8177, 1.2701, 0.9721]],\n",
       "\n",
       "        [[0.5868, 0.6250, 1.4764, 0.5411],\n",
       "         [1.3735, 0.9741, 1.0492, 1.1260]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape: (3, 1, 4)\n",
    "a = torch.rand(3, 1, 4)\n",
    "# Shape: (2, 4) - aligned from right: (1, 2, 4) vs (3, 1, 4)\n",
    "b = torch.rand(2, 4)\n",
    "\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5369386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b081b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
