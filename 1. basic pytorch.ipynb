{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf12335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.functional as F \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1bfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# This is a vector\n",
    "\n",
    "a = torch.tensor([\n",
    "    1,2,3,4,5\n",
    "])\n",
    "print(a.ndim)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e5a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# This is a MATRIX\n",
    "\n",
    "b = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [3,2,4,5]\n",
    "])\n",
    "print(a.ndim)\n",
    "print( a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4efe6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# THIS IS A TENSOR\n",
    "\n",
    "c = torch.tensor([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]\n",
    "])\n",
    "print(c.ndim)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358090b7",
   "metadata": {},
   "source": [
    "| **Name**  | **What is it?**                                                                 | **Number of dimensions** | **Lower or upper (usually/example)** |\n",
    "|-----------|----------------------------------------------------------------------------------|---------------------------|----------------------------------------|\n",
    "| **scalar**| a single number                                                                  | 0                         | Lower ( *a* )                          |\n",
    "| **vector**| a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1                         | Lower ( *y* )                          |\n",
    "| **matrix**| a 2-dimensional array of numbers                                                 | 2                         | Upper ( *Q* )                          |\n",
    "| **tensor**| an n-dimensional array of numbers. Can be any number. A 0-dim tensor is a scalar, a 1-dim tensor is a vector | n                         | Upper ( *X* )                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95218fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1417, 0.8812, 0.7229],\n",
       "        [0.8477, 0.3155, 0.9697]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîπ 1. torch.rand()\n",
    "\n",
    "# ‚û§ What it does:\n",
    "# Returns a tensor filled with random numbers from a uniform distribution over [0, 1).\n",
    "\n",
    "d = torch.rand\n",
    "d\n",
    "\n",
    "# ‚û§ Use when:\n",
    "# You need values between 0 and 1 (e.g., initializing weights, dropout masks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814faf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9868,  0.9877, -1.1945],\n",
       "        [ 0.5119, -0.2236,  0.7186]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîπ 2. torch.randn()\n",
    "\n",
    "# ‚û§ What it does:\n",
    "# Returns a tensor filled with random numbers from a normal (Gaussian) distribution, with mean = 0 and std = 1.\n",
    "\n",
    "d = torch.randn(2,3)\n",
    "d\n",
    "\n",
    "# ‚û§ Use when:\n",
    "# You want random noise or weight initialization centered around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38998e5e",
   "metadata": {},
   "source": [
    "| Function             | Distribution    | Range   | Shape Source | Typical Use Case                 |\n",
    "| -------------------- | --------------- | ------- | ------------ | -------------------------------- |\n",
    "| `torch.rand()`       | Uniform         | \\[0, 1) | Manual       | Weights, probabilities           |\n",
    "| `torch.randn()`      | Normal (mean=0) | (-‚àû, ‚àû) | Manual       | Noise, weight init               |\n",
    "| `torch.rand_like()`  | Uniform         | \\[0, 1) | Like input   | Dropout, masks like input tensor |\n",
    "| `torch.randn_like()` | Normal (mean=0) | (-‚àû, ‚àû) | Like input   | Add noise to activations, etc.   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5821c",
   "metadata": {},
   "source": [
    "| Term | Meaning                        | Effect on Distribution     |\n",
    "| ---- | ------------------------------ | -------------------------- |\n",
    "| Mean | Central value (Œº)              | Shifts curve left/right    |\n",
    "| Std  | Standard deviation (œÉ)         | Stretches/squeezes curve   |\n",
    "| 0, 1 | \"Standard normal\" distribution | Default in `torch.randn()` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3242daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# zeros and ones \n",
    "\n",
    "\n",
    "a = torch.zeros(3,4)\n",
    "print(a)\n",
    "\n",
    "b = torch.randn(4,4)\n",
    "c = torch.zeros_like(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb0f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.ones(2,3)\n",
    "e = torch.ones_like(b)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40e21b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "        0.9000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING A RANGE OF TENSORS\n",
    "\n",
    "a = torch.arange(start=0, end=1, step=0.1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60a2c345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING A RANGE OF TENSORS\n",
    "\n",
    "a = torch.arange(start=0, end=1, step=0.25)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d9b10",
   "metadata": {},
   "source": [
    "\n",
    "## üî∏ Basic Tensor Arithmetic\n",
    "\n",
    "### ‚û§ Common Operators:\n",
    "\n",
    "| Operation      | Symbol | Function      | Example       |\n",
    "| -------------- | ------ | ------------- | ------------- |\n",
    "| Addition       | `+`    | `torch.add()` | `tensor + 10` |\n",
    "| Subtraction    | `-`    | `torch.sub()` | `tensor - 10` |\n",
    "| Multiplication | `*`    | `torch.mul()` | `tensor * 10` |\n",
    "| Division       | `/`    | `torch.div()` | `tensor / 10` |\n",
    "\n",
    "### ‚û§ Element-wise Example:\n",
    "\n",
    "```python\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10           # tensor([11, 12, 13])\n",
    "tensor * 10           # tensor([10, 20, 30])\n",
    "tensor * tensor       # tensor([1, 4, 9])\n",
    "```\n",
    "\n",
    "**Important:** Tensors do not mutate unless reassigned.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ Matrix Multiplication (The Core of Deep Learning)\n",
    "\n",
    "### ‚û§ Core Function:\n",
    "\n",
    "```python\n",
    "torch.matmul(A, B)  # or simply A @ B\n",
    "```\n",
    "\n",
    "### ‚û§ Rules:\n",
    "\n",
    "* **Inner dimensions must match**: `(m x n) @ (n x p)` ‚úÖ\n",
    "* **Output shape**: `(m x p)`\n",
    "\n",
    "### ‚û§ Example:\n",
    "\n",
    "```python\n",
    "A = torch.tensor([1, 2, 3])\n",
    "A @ A         # 1*1 + 2*2 + 3*3 = 14\n",
    "```\n",
    "\n",
    "### ‚û§ Tensor Matrix Shapes:\n",
    "\n",
    "```python\n",
    "tensor_A: (3 x 2)\n",
    "tensor_B: (3 x 2) ‚ùå\n",
    "tensor_B.T: (2 x 3) ‚úÖ\n",
    "torch.matmul(tensor_A, tensor_B.T)  # (3 x 2) @ (2 x 3) -> (3 x 3)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ Shape Errors & Transpose\n",
    "\n",
    "* Most common PyTorch error: **shape mismatch** in matrix operations.\n",
    "* Fix using:\n",
    "\n",
    "```python\n",
    "torch.transpose(tensor, 0, 1)\n",
    "tensor.T  # shorthand\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66d665f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# üî∏ 1. torch.reshape() ‚Äî Change the shape\n",
    "# Changes the shape of a tensor (as long as the total number of elements stays the same).\n",
    "\n",
    "x = torch.arange(6)         # tensor([0, 1, 2, 3, 4, 5])\n",
    "x_reshaped = torch.reshape(x, (2, 3))      # or we can also do x.reshape(2,3)\n",
    "print(x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "299bdf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# üî∏ 2. tensor.view() ‚Äî Like reshape but faster\n",
    "# Creates a view (shared memory) of a tensor in a new shape.\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "viewed = x.view(3, 2)\n",
    "print(viewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24cafb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# üî∏ 3. torch.stack() ‚Äî Stack tensors along a new dim\n",
    "# Used in multi-head attention, batch creation, etc.\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "stacked = torch.stack([a, b], dim=0)  # New 0-th dimension\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10677fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1])\n",
      "torch.Size([3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# üî∏ 4. torch.squeeze() ‚Äî Remove dims of size 1\n",
    "# Cleans up shape. Often used after models.\n",
    "\n",
    "x = torch.tensor([[[1], [2], [3]]])\n",
    "print(x.shape)             # (1, 3, 1)\n",
    "print(torch.squeeze(x).shape)  # (3,)\n",
    "print(torch.squeeze(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "tensor([[1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "# üî∏ 5. torch.unsqueeze() ‚Äî Add a 1-dim\n",
    "# Prepares data for broadcasting or adding batch/time/head dims.\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_unsq = torch.unsqueeze(x, 0)\n",
    "print(x_unsq.shape)  # torch.Size([1, 3])\n",
    "print(x_unsq)\n",
    "\n",
    "# üß† Used in attention like:\n",
    "# (batch, seq_len) ‚Üí (batch, 1, seq_len) to match matrix shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c65835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8863, 0.7747, 0.7695, 0.5216],\n",
      "         [0.4060, 0.1577, 0.3718, 0.7764],\n",
      "         [0.0636, 0.6644, 0.3799, 0.9512]],\n",
      "\n",
      "        [[0.6755, 0.0513, 0.0047, 0.6641],\n",
      "         [0.8687, 0.3457, 0.8124, 0.3000],\n",
      "         [0.8270, 0.1543, 0.2062, 0.5369]]])\n",
      "torch.Size([2, 4, 3])\n",
      "\n",
      "\n",
      "tensor([[[0.8863, 0.4060, 0.0636],\n",
      "         [0.7747, 0.1577, 0.6644],\n",
      "         [0.7695, 0.3718, 0.3799],\n",
      "         [0.5216, 0.7764, 0.9512]],\n",
      "\n",
      "        [[0.6755, 0.8687, 0.8270],\n",
      "         [0.0513, 0.3457, 0.1543],\n",
      "         [0.0047, 0.8124, 0.2062],\n",
      "         [0.6641, 0.3000, 0.5369]]])\n"
     ]
    }
   ],
   "source": [
    "# üî∏ 6. torch.permute() ‚Äî Reorder dimensions\n",
    "# Absolutely crucial for attention where dimension order matters.\n",
    "\n",
    "x = torch.rand(2, 3, 4)  # (batch, seq_len, features)\n",
    "print(x)\n",
    "x_perm = x.permute(0, 2, 1)\n",
    "print(x_perm.shape)  # torch.Size([2, 4, 3])\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(x_perm)\n",
    "\n",
    "\n",
    "# How the above example worked\n",
    "# when we permute the 2nd and 3rd dimension , we just make the rows into columns\n",
    "\n",
    "\n",
    "# üß† Why care?\n",
    "# Transformers expect inputs in (batch, heads, seq_len, head_dim)\n",
    "# Attention scores require precise shape alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802228d",
   "metadata": {},
   "source": [
    "| Function    | Purpose                               | Example Shape Change  |\n",
    "| ----------- | ------------------------------------- | --------------------- |\n",
    "| `reshape`   | Change shape                          | (6,) ‚Üí (2, 3)         |\n",
    "| `view`      | Same as reshape, faster when possible | (2, 3) ‚Üí (3, 2)       |\n",
    "| `unsqueeze` | Add 1 dim                             | (3,) ‚Üí (1, 3)         |\n",
    "| `squeeze`   | Remove 1-dims                         | (1, 3, 1) ‚Üí (3,)      |\n",
    "| `stack`     | Stack along new dim                   | \\[a, b] (3,) ‚Üí (2, 3) |\n",
    "| `permute`   | Reorder dims                          | (B, S, H) ‚Üí (B, H, S) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63400651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Visual Explanation:\n",
    "# Let‚Äôs assume a tensor with shape (2, 3, 4) representing:\n",
    "# 2 images\n",
    "# 3 rows (height)\n",
    "# 4 columns (width)\n",
    "# Original Shape: (H, W, C) = (224, 224, 3)\n",
    "\n",
    "# Before:\n",
    "#   Axis 0: Height ‚Üí 224 rows\n",
    "#   Axis 1: Width  ‚Üí 224 columns\n",
    "#   Axis 2: Channels ‚Üí [R, G, B]\n",
    "\n",
    "# After permute(2, 0, 1):\n",
    "#   Axis 0: Channels ‚Üí Now first axis (3)\n",
    "#   Axis 1: Height   ‚Üí Now second axis (224)\n",
    "#   Axis 2: Width    ‚Üí Now third axis (224)\n",
    "# You're not changing the pixel values ‚Äî you're just changing how you're reading them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# üí° TL;DR Intuition\n",
    "# permute() is like rotating the axes of a Rubik's cube ‚Äî it changes how you look at the data, not the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02897f22",
   "metadata": {},
   "source": [
    "| Action        | What Happens                                         |\n",
    "| ------------- | ---------------------------------------------------- |\n",
    "| `permute()`   | Changes axis **order** only (no copying)             |\n",
    "| `reshape()`   | Changes shape (requires same # elements)             |\n",
    "| `view()`      | Same as reshape but faster (if memory layout allows) |\n",
    "| `transpose()` | Special case of permute (only 2 dims swapped)        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df165609",
   "metadata": {},
   "source": [
    "## Accessing data from tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03da77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5384db3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bd8ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11ea77",
   "metadata": {},
   "source": [
    "# : based indexing \n",
    "\n",
    "| Indexing        | What it means                              |\n",
    "| --------------- | ------------------------------------------ |\n",
    "| `:`             | All values in that dimension               |\n",
    "| `0`             | Just the first item                        |\n",
    "| `:` + `,` combo | Helps you slice across multiple dimensions |\n",
    "| `x[:, 1]`       | All rows, column 1                         |\n",
    "| `x[0, :]`       | Row 0, all columns                         |\n",
    "| `x[:, :, 0]`    | All blocks, all rows, column 0             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b34736",
   "metadata": {},
   "source": [
    "üß† What : Can Do Alone\n",
    "The colon : is shorthand for:\n",
    "start:stop:step\n",
    "Where:\n",
    "start is the starting index (default = 0)\n",
    "stop is the ending index (excluded)\n",
    "step is how much to jump (default = 1)\n",
    "\n",
    "\n",
    "x = torch.tensor([10, 20, 30, 40, 50, 60])\n",
    "\n",
    "\n",
    "| Code      | Meaning                          | Output                     |\n",
    "| --------- | -------------------------------- | -------------------------- |\n",
    "| `x[:]`    | All elements                     | `[10, 20, 30, 40, 50, 60]` |\n",
    "| `x[::2]`  | Every 2nd element (step = 2)     | `[10, 30, 50]`             |\n",
    "| `x[1:]`   | From index 1 to end              | `[20, 30, 40, 50, 60]`     |\n",
    "| `x[:4]`   | From start to index 4 (excluded) | `[10, 20, 30, 40]`         |\n",
    "| `x[::-1]` | Reverse the tensor               | `[60, 50, 40, 30, 20, 10]` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cd011",
   "metadata": {},
   "source": [
    "# Advanced Tensor Operations\n",
    "\n",
    "## Broadcasting\n",
    "üîë What is Broadcasting?\n",
    "\n",
    "Broadcasting allows tensors with different shapes to be used together in arithmetic operations (like +, -, *, /) without explicitly reshaping them.\n",
    "\n",
    "| A.shape   | B.shape   | A op B Valid? | Result shape |\n",
    "| --------- | --------- | ------------- | ------------ |\n",
    "| (5, 3)    | (1, 3)    | ‚úÖ             | (5, 3)       |\n",
    "| (3,)      | (5, 3)    | ‚úÖ             | (5, 3)       |\n",
    "| (1, 4, 3) | (7, 1, 3) | ‚úÖ             | (7, 4, 3)    |\n",
    "| (5, 3, 2) | (3, 2)    | ‚úÖ             | (5, 3, 2)    |\n",
    "| (3, 1, 4) | (2, 4)    | ‚ùå             | ‚ùå            |\n",
    "\n",
    "## Rule Summary:\n",
    "####  Align shapes from the rightmost dimension.\n",
    "####  Dimensions must be either equal or 1.\n",
    "####  If one is 1, it is broadcast (repeated) to match the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "459d42ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3, 2)   # Shape: (4, 3, 2)\n",
    "b = torch.rand(1, 3, 1)   # Shape: (1, 3, 1)\n",
    "\n",
    "result = a + b\n",
    "print(result.shape)  # ‚ûú (4, 3, 2)\n",
    "\n",
    "# Why?\n",
    "# a: (4, 3, 2)\n",
    "# b: (1, 3, 1) ‚Üí can stretch to match (4, 3, 2)\n",
    "# Insight: Singleton dimensions are \"stretchable\" in broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edde8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4, 3, 2)\n",
    "b = torch.rand(4, 2, 3)\n",
    "\n",
    "# a + b  # RuntimeError!\n",
    "\n",
    "\n",
    "# Why? Shapes from right:\n",
    "# (2) vs (3) ‚Üí mismatch\n",
    "# (3) vs (2) ‚Üí mismatch\n",
    "# No rule allows this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef9769",
   "metadata": {},
   "source": [
    "#### üéØ Example: Apply bias in multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b53d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 128])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input from attention\n",
    "x = torch.rand(32, 8, 128)  # (batch, heads, dim)\n",
    "\n",
    "# Learnable bias for each head\n",
    "bias = torch.rand(8, 128)   # (heads, dim)\n",
    "\n",
    "# Automatically broadcast along batch dimension\n",
    "x = x + bias  # Result: (32, 8, 128)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10058bc",
   "metadata": {},
   "source": [
    "#### ‚ú® üî∏ Level 3: System-Level + Manual Broadcasting\n",
    "üß† How PyTorch Broadcasting Actually Works (Under the Hood)\n",
    "\n",
    "Step-by-step rules:\n",
    "\n",
    "Given two shapes A and B:\n",
    "\n",
    "- Right-align dimensions.\n",
    "- For each dim (right to left):\n",
    "    - If equal, OK.\n",
    "    - If one is 1, expand it.\n",
    "    - Else, Error.\n",
    "\n",
    "PyTorch expands the smaller tensor without copying data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8997ca82",
   "metadata": {},
   "source": [
    "#### üîß Manually Forcing Broadcasting (Power user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7ac21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .unsqueeze() to align dimensions\n",
    "\n",
    "x = torch.rand(64, 10)     # (64, 10)\n",
    "w = torch.rand(10)         # (10,) ‚Üí needs to be (1, 10)\n",
    "\n",
    "# Manual broadcast\n",
    "p = x + w.unsqueeze(0)         # (64, 10)\n",
    "\n",
    "p.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c64b27",
   "metadata": {},
   "source": [
    "### üîß expand() vs repeat() ‚Äî Key Differences\n",
    "\n",
    "| Feature           | `expand()`                   | `repeat()`                       |\n",
    "| ----------------- | ---------------------------- | -------------------------------- |\n",
    "| Copies memory?    | ‚ùå No (view-based)            | ‚úÖ Yes (real copy)                |\n",
    "| Speed             | ‚ö° Fast                       | üê¢ Slower                        |\n",
    "| Memory usage      | üß† Efficient                 | üíæ Uses more memory              |\n",
    "| Use case          | For safe broadcasting        | For full tiling (repeat content) |\n",
    "| Shape restriction | Only works if dimension is 1 | Works on any shape               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19a0ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ expand() ‚Äî stretch without copying\n",
    "# Use when:\n",
    "# You want to simulate broadcasting manually.\n",
    "\n",
    "\n",
    "x = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "\n",
    "x_exp = x.expand(3, 4)            # Expand to (3, 4)\n",
    "print(x_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60701d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Rule:\n",
    "# Only expands along dimensions where original size is 1.\n",
    "# The new size must be equal or greater, and the old size must be 1 or same.\n",
    "\n",
    "\n",
    "x = torch.rand(2, 1, 3)\n",
    "x.expand(2, 4, 3)  # ‚úÖ works (1 ‚Üí 4)\n",
    "x.expand(3, 4, 3)  # ‚ùå fails (2 ‚â† 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2fc4d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ repeat() ‚Äî full content duplication\n",
    "# Use when:\n",
    "# You want to tile the content ‚Äî actually make a bigger tensor with copied data.\n",
    "\n",
    "x = torch.tensor([[1], [2], [3]])  # (3, 1)\n",
    "\n",
    "x_rep = x.repeat(1, 4)             # Repeat 4 times along columns\n",
    "print(x_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc712a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
    "x.repeat(2)                  # Repeats entire tensor 2 times ‚Üí (6,)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eff7f8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 2, 1, 2],\n",
       "        [3, 4, 3, 4, 3, 4],\n",
       "        [1, 2, 1, 2, 1, 2],\n",
       "        [3, 4, 3, 4, 3, 4]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])  # (2, 2)\n",
    "x.repeat(2, 3)                      # Repeat rows 2√ó and columns 3√ó ‚Üí (4, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "24940bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3]])  # Shape: (3,1)\n",
    "# Make it (3, 4, 2) using unsqueeze + expand\n",
    "\n",
    "y = x.unsqueeze(-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97769bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.expand(3,4,2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1], [2], [3]])\n",
    "x.size()\n",
    "torch.Size([3, 1])\n",
    "x.expand(3, 4)\n",
    "# tensor([[ 1,  1,  1,  1],\n",
    "#         [ 2,  2,  2,  2],\n",
    "#         [ 3,  3,  3,  3]])\n",
    "x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
    "# tensor([[ 1,  1,  1,  1],\n",
    "#         [ 2,  2,  2,  2],\n",
    "#         [ 3,  3,  3,  3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3de92",
   "metadata": {},
   "source": [
    "### üîπ repeat_interleave() = element-level repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30cd92e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x_repint = x.repeat_interleave(2)\n",
    "print(x_repint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06beac",
   "metadata": {},
   "source": [
    "\n",
    "### üß† Key Intuition\n",
    "- expand is like saying: \"Hey PyTorch, just pretend it's bigger by repeating along axis ‚Äî don't actually do it.\"\n",
    "- repeat is: \"Make actual copies in memory. I need a real big tensor now.\"\n",
    "- repeat_interleave is: \"Repeat individual elements, not the whole structure.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ed260",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
